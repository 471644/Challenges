{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ** This notebook consist of my work on pre-processing the data-set for modeling.\n",
    "    ** Some of the common text preprocessing / cleaning steps are:\n",
    "\n",
    "                Lower casing\n",
    "                Removal of Punctuations\n",
    "                Removal of Stopwords\n",
    "                Removal of Frequent words\n",
    "                Removal of Rare words\n",
    "                Stemming\n",
    "                Lemmatization\n",
    "                Removal of emojis\n",
    "                Removal of emoticons\n",
    "                Conversion of emoticons to words\n",
    "                Conversion of emojis to words\n",
    "                Removal of URLs\n",
    "                Removal of HTML tags\n",
    "                Chat words conversion\n",
    "                Spelling correction\n",
    "                \n",
    "    ** So these are the different types of text preprocessing steps which we can do on text data.\n",
    "      But, one need not do all of these all the times. \n",
    "      One needs to carefully choose the preprocessing steps based on our use case since that also play an important role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:35:30.962904Z",
     "start_time": "2021-05-29T12:35:30.950936Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:39:46.276862Z",
     "start_time": "2021-05-29T12:39:45.848716Z"
    }
   },
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:54:13.551009Z",
     "start_time": "2021-05-29T12:52:46.772717Z"
    }
   },
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:48:32.221913Z",
     "start_time": "2021-05-29T12:48:32.051724Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('max_colwidth', 999)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option(\"display.max_rows\", 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:36:06.669019Z",
     "start_time": "2021-05-29T12:36:06.590168Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:\\\\Users\\\\Zeus\\\\Downloads\\\\HackerEarth\\\\dataset\\\\hm_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:36:24.015058Z",
     "start_time": "2021-05-29T12:36:24.000357Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60321, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>1</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid reflection_period                                         cleaned_hm  \\\n",
       "0  27673               24h  I went on a successful date with someone I fel...   \n",
       "1  27674               24h  I was happy when my son got 90% marks in his e...   \n",
       "2  27675               24h       I went to the gym this morning and did yoga.   \n",
       "3  27676               24h  We had a serious talk with some friends of our...   \n",
       "4  27677               24h  I went with grandchildren to butterfly display...   \n",
       "\n",
       "   num_sentence predicted_category  \n",
       "0             1          affection  \n",
       "1             1          affection  \n",
       "2             1           exercise  \n",
       "3             2            bonding  \n",
       "4             1          affection  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:43:26.520579Z",
     "start_time": "2021-05-29T12:43:26.465508Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40213, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>num_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88305</td>\n",
       "      <td>3m</td>\n",
       "      <td>I spent the weekend in Chicago with my friends.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88306</td>\n",
       "      <td>3m</td>\n",
       "      <td>We moved back into our house after a remodel. ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88307</td>\n",
       "      <td>3m</td>\n",
       "      <td>My fiance proposed to me in front of my family...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88308</td>\n",
       "      <td>3m</td>\n",
       "      <td>I ate lobster at a fancy restaurant with some ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88309</td>\n",
       "      <td>3m</td>\n",
       "      <td>I went out to a nice restaurant on a date with...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid reflection_period                                         cleaned_hm  \\\n",
       "0  88305                3m    I spent the weekend in Chicago with my friends.   \n",
       "1  88306                3m  We moved back into our house after a remodel. ...   \n",
       "2  88307                3m  My fiance proposed to me in front of my family...   \n",
       "3  88308                3m  I ate lobster at a fancy restaurant with some ...   \n",
       "4  88309                3m  I went out to a nice restaurant on a date with...   \n",
       "\n",
       "   num_sentence  \n",
       "0             1  \n",
       "1             2  \n",
       "2             1  \n",
       "3             1  \n",
       "4             5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"C:\\\\Users\\\\Zeus\\\\Downloads\\\\HackerEarth\\\\dataset\\\\hm_test.csv\")\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:36:55.998547Z",
     "start_time": "2021-05-29T12:36:55.962811Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "affection           20880\n",
       "achievement         20274\n",
       "bonding              6561\n",
       "enjoy_the_moment     6508\n",
       "leisure              4242\n",
       "nature               1127\n",
       "exercise              729\n",
       "Name: predicted_category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.predicted_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:39:32.665849Z",
     "start_time": "2021-05-29T12:39:32.660862Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_mapping = {\n",
    "    'affection': 1,\n",
    "    'achievement': 2,\n",
    "    'bonding': 3,\n",
    "    'enjoy_the_moment': 4,\n",
    "    'leisure': 5,\n",
    "    'nature': 6,\n",
    "    'exercise': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:40:54.370842Z",
     "start_time": "2021-05-29T12:40:54.260569Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058e7b46e93b43de95a873bbe2197427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=60321.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train['target'] = train.predicted_category.swifter.apply(lambda x:target_mapping[x]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:41:04.082465Z",
     "start_time": "2021-05-29T12:41:04.068652Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hmid                   int64\n",
       "reflection_period     object\n",
       "cleaned_hm            object\n",
       "num_sentence           int64\n",
       "predicted_category    object\n",
       "target                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## reflection_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:42:26.997462Z",
     "start_time": "2021-05-29T12:42:26.985492Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24h    30455\n",
       "3m     29866\n",
       "Name: reflection_period, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reflection_period.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:43:39.587611Z",
     "start_time": "2021-05-29T12:43:39.570660Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3m     20837\n",
       "24h    19376\n",
       "Name: reflection_period, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.reflection_period.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaned_hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:45:52.319687Z",
     "start_time": "2021-05-29T12:45:52.307364Z"
    }
   },
   "outputs": [],
   "source": [
    "train['cleaned_hm'] = train.cleaned_hm.astype(str).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:46:09.922710Z",
     "start_time": "2021-05-29T12:46:09.901764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>1</td>\n",
       "      <td>exercise</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid reflection_period                                         cleaned_hm  \\\n",
       "0  27673               24h  I went on a successful date with someone I fel...   \n",
       "1  27674               24h  I was happy when my son got 90% marks in his e...   \n",
       "2  27675               24h       I went to the gym this morning and did yoga.   \n",
       "3  27676               24h  We had a serious talk with some friends of our...   \n",
       "4  27677               24h  I went with grandchildren to butterfly display...   \n",
       "\n",
       "   num_sentence predicted_category  target  \n",
       "0             1          affection       1  \n",
       "1             1          affection       1  \n",
       "2             1           exercise       7  \n",
       "3             2            bonding       3  \n",
       "4             1          affection       1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Lower Case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:50:47.015115Z",
     "start_time": "2021-05-29T12:50:46.985016Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[\"pre_processed_clean_hm\"] = train[\"cleaned_hm\"].str.lower().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Removal Of Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:50:48.398275Z",
     "start_time": "2021-05-29T12:50:48.384230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    PUNCT_TO_REMOVE = string.punctuation\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:50:49.535682Z",
     "start_time": "2021-05-29T12:50:49.247040Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d215498ca26d46409b203a9536ecd094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=60321.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train[\"pre_processed_clean_hm\"] = train[\"pre_processed_clean_hm\"].swifter.apply(\n",
    "    lambda text: remove_punctuation(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Removal Of Stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:51:43.063402Z",
     "start_time": "2021-05-29T12:51:43.046529Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    return \" \".join(\n",
    "        [word for word in str(text).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:57:20.336051Z",
     "start_time": "2021-05-29T12:57:10.160158Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37571267b014443baa5e06e06403852f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=60321.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train[\"pre_processed_clean_hm\"] = train[\"pre_processed_clean_hm\"].swifter.apply(\n",
    "    lambda text: remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Removal of Frequent & Rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:59:00.963140Z",
     "start_time": "2021-05-29T12:59:00.787995Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('happy', 11877),\n",
       " ('got', 8107),\n",
       " ('made', 7208),\n",
       " ('went', 5990),\n",
       " ('time', 5555),\n",
       " ('new', 5209),\n",
       " ('work', 4673),\n",
       " ('day', 4506),\n",
       " ('last', 3768),\n",
       " ('friend', 3568)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter()\n",
    "for text in train[\"pre_processed_clean_hm\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "del text,word        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T12:59:50.447717Z",
     "start_time": "2021-05-29T12:59:50.431759Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acquit',\n",
       " 'cashstrapped',\n",
       " 'exonerate',\n",
       " 'fabiola',\n",
       " 'netting',\n",
       " 'ought',\n",
       " 'spout',\n",
       " 'thumping',\n",
       " 'willeford',\n",
       " 'wondrous'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([w for (w, wc) in cnt.most_common()[:-10-1:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    ** looking at the most frequent and most rare words I would skip this pre-processing steps as these words contain important information and will be helpful during the word embedding process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ** Lemmatization is similar to stemming in reducing inflected words to their word stem but differs in the way that it makes sure the root word (also called as lemma) belongs to the language.\n",
    "    As a result, this one is generally slower than stemming process. However, based on my experience I have observed lemmatization work better than stemming hence, I would opt this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ** Also, in this context good || better || best can be associated to different classes in the targets hence, lemmatization help in keeping all these variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T13:06:54.333786Z",
     "start_time": "2021-05-29T13:06:54.321817Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    wordnet_map = {\n",
    "        \"N\": wordnet.NOUN,\n",
    "        \"V\": wordnet.VERB,\n",
    "        \"J\": wordnet.ADJ,\n",
    "        \"R\": wordnet.ADV\n",
    "    }\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([\n",
    "        lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN))\n",
    "        for word, pos in pos_tagged_text\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T13:08:17.008939Z",
     "start_time": "2021-05-29T13:07:32.801662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1460681100416bb2adf8038516978d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=60321.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train[\"pre_processed_clean_hm\"] = train[\"pre_processed_clean_hm\"].swifter.apply(\n",
    "    lambda text: lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoji Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ** Emoji Realted Pre-Processing is Not Required for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Word Conversion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ** There might be the case where while writing the moment folks might have used chat related short forms so to handle these we will do proper pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T13:12:53.473456Z",
     "start_time": "2021-05-29T13:12:53.466475Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_words_str = \"\"\"\n",
    "AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T13:13:49.073948Z",
     "start_time": "2021-05-29T13:13:49.063975Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_words_map_dict = {}\n",
    "chat_words_list = []\n",
    "for line in chat_words_str.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        cw = line.split(\"=\")[0]\n",
    "        cw_expanded = line.split(\"=\")[1]\n",
    "        chat_words_list.append(cw)\n",
    "        chat_words_map_dict[cw] = cw_expanded\n",
    "chat_words_list = set(chat_words_list)\n",
    "del line,cw,cw_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T13:14:24.249603Z",
     "start_time": "2021-05-29T13:14:24.231651Z"
    }
   },
   "outputs": [],
   "source": [
    "def chat_words_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words_list:\n",
    "            new_text.append(chat_words_map_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T13:14:43.962833Z",
     "start_time": "2021-05-29T13:14:43.706232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6f624ae2a44459931e5ea75e70c46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=60321.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train[\"pre_processed_clean_hm\"] = train[\"pre_processed_clean_hm\"].swifter.apply(\n",
    "    lambda text: chat_words_conversion(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Checker "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    One another important text preprocessing step is spelling correction. Typos are common in text data and we might want to correct those spelling mistakes before we do our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T13:16:13.980279Z",
     "start_time": "2021-05-29T13:16:13.966313Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_spellings(text):\n",
    "    spell = SpellChecker()\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T13:25:03.054799Z",
     "start_time": "2021-05-29T13:16:28.680100Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"pre_processed_clean_hm\"] = train[\"pre_processed_clean_hm\"].swifter.apply(\n",
    "    lambda text: correct_spellings(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T13:14:49.327687Z",
     "start_time": "2021-05-29T13:14:49.314709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>target</th>\n",
       "      <th>pre_processed_clean_hm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I felt sympathy and connection with.</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>1</td>\n",
       "      <td>go successful date someone felt sympathy connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his examination</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>1</td>\n",
       "      <td>happy son get 90 mark examination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>1</td>\n",
       "      <td>exercise</td>\n",
       "      <td>7</td>\n",
       "      <td>go gym morning yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of ours who have been flaky lately. They understood and we had a good evening hanging out.</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>3</td>\n",
       "      <td>serious talk friend flaky lately understood good evening hanging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display at Crohn Conservatory\\r\\r\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>1</td>\n",
       "      <td>go grandchild butterfly display crohn conservatory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid reflection_period  \\\n",
       "0  27673               24h   \n",
       "1  27674               24h   \n",
       "2  27675               24h   \n",
       "3  27676               24h   \n",
       "4  27677               24h   \n",
       "\n",
       "                                                                                                                           cleaned_hm  \\\n",
       "0                                                       I went on a successful date with someone I felt sympathy and connection with.   \n",
       "1                                                                           I was happy when my son got 90% marks in his examination    \n",
       "2                                                                                        I went to the gym this morning and did yoga.   \n",
       "3  We had a serious talk with some friends of ours who have been flaky lately. They understood and we had a good evening hanging out.   \n",
       "4                                                          I went with grandchildren to butterfly display at Crohn Conservatory\\r\\r\\n   \n",
       "\n",
       "   num_sentence predicted_category  target  \\\n",
       "0             1          affection       1   \n",
       "1             1          affection       1   \n",
       "2             1           exercise       7   \n",
       "3             2            bonding       3   \n",
       "4             1          affection       1   \n",
       "\n",
       "                                             pre_processed_clean_hm  \n",
       "0               go successful date someone felt sympathy connection  \n",
       "1                                 happy son get 90 mark examination  \n",
       "2                                               go gym morning yoga  \n",
       "3  serious talk friend flaky lately understood good evening hanging  \n",
       "4                go grandchild butterfly display crohn conservatory  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "724.219px",
    "left": "1644.33px",
    "right": "20px",
    "top": "115px",
    "width": "291.771px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
